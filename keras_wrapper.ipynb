{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from typing import Tuple\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def bathrooms_featurizer(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"map bagni 1, 2, else to 0, 1, 2\"\"\"\n",
    "    mapping = {1: 0, 2: 1}\n",
    "    bathrooms = df['bagni'].map(mapping).fillna(2)\n",
    "    return bathrooms\n",
    "\n",
    "def rooms_featurizer(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"map stanze 1, 2, 3, else to 0, 1, 2, 3\"\"\"\n",
    "    mapping = {1: 0, 2: 1, 3: 2}\n",
    "    rooms = df['stanze'].map(mapping).fillna(3)\n",
    "    return rooms\n",
    "\n",
    "CUSTOM_FEATURE_FUNCTIONS = {\n",
    "    \"bathrooms_feature\": bathrooms_featurizer,\n",
    "    \"rooms_feature\": rooms_featurizer,\n",
    "}\n",
    "\n",
    "class PandasFeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Featurize DataFrame by applying specified functions and return only the series.\"\"\"\n",
    "\n",
    "    CUSTOM_FEATURE_FUNCTIONS = {\n",
    "        \"bathrooms_feature\": bathrooms_featurizer,\n",
    "        \"rooms_feature\": rooms_featurizer,\n",
    "        }\n",
    "\n",
    "    def __init__(self, functions=None):\n",
    "        self.functions = functions\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        if not isinstance(df, pd.DataFrame):\n",
    "            raise TypeError(\"Input must be a DataFrame.\")\n",
    "        \n",
    "        df_transformed = pd.DataFrame()\n",
    "        for func_name, func in self.functions.items():\n",
    "            df_transformed[func_name] = func(df)\n",
    "\n",
    "        return df_transformed\n",
    "\n",
    "        # # If there's only one function, return its output directly.\n",
    "        # # Otherwise, concatenate the outputs column-wise.\n",
    "        # if len(output) == 1:\n",
    "        #     return output[0].values.reshape(-1, 1)\n",
    "        # else:\n",
    "        #     return np.column_stack(output)\n",
    "\n",
    "\n",
    "class PandasColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Select a sub-set of columns from a pandas DataFrame.\"\"\"\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, df, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        return df[self.columns].copy()\n",
    "    \n",
    "\n",
    "def build_model(\n",
    "    *,\n",
    "    # Features & labels\n",
    "    num_features: int,\n",
    "    num_labels: int,\n",
    "    # Network architecture\n",
    "    hidden_units: Tuple[int, ...],\n",
    "    dropout_rate: float | None = None,\n",
    "    # Other wrapper induced parameters,\n",
    "    **kwargs,\n",
    ") -> Model:\n",
    "    features = Input(shape=(num_features,), name=\"features\")\n",
    "\n",
    "    layers = features\n",
    "    for idx, units in enumerate(hidden_units):\n",
    "        layers = Dense(units, activation=\"relu\", name=f\"dense_{idx}\")(layers)\n",
    "        if dropout_rate:\n",
    "            layers = Dropout(dropout_rate, name=f\"dropout_{idx}\")(layers)\n",
    "\n",
    "    labels = Dense(num_labels, name=\"labels\")(layers)\n",
    "\n",
    "    model = Model(features, labels)\n",
    "    model.compile(**kwargs[\"compile_kwargs\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "class KerasRegressorWrapper(KerasRegressor):\n",
    "\n",
    "    def __init__(self, my_param=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.my_param = my_param\n",
    "\n",
    "    @property\n",
    "    def target_encoder(self) -> BaseEstimator:\n",
    "        return StandardScaler()\n",
    "\n",
    "    @staticmethod\n",
    "    def scorer(y_true, y_pred, **kwargs) -> float:\n",
    "        return mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "\n",
    "# A simple function to reshape a 1D array to 2D\n",
    "class TargetReshaper(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, y):\n",
    "        # Convert y to a 2D array\n",
    "        return y.values.reshape(-1, 1)\n",
    "\n",
    "    def inverse_transform(self, y):\n",
    "        # Convert y back to a 1D array\n",
    "        return y.ravel()\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_parquet('../dataframes/rents_clean.parquet')\n",
    "df = df.dropna(subset=['prezzo', 'superficie'])\n",
    "df = df.loc[df['prezzo'] < 10000]\n",
    "\n",
    "numerical_features = ['superficie']\n",
    "categorical_features = [\n",
    "    'posti auto', 'bagni', 'stanze', 'ultimo piano', 'stato',\n",
    "    'classe energetica', 'riscaldamento centralizzato', 'arredato', 'balcone', 'esposizione esterna', 'fibra ottica', 'cancello elettrico', 'cantina', 'giardino comune', 'giardino privato', 'piscina', 'villa', 'intera proprieta', 'appartamento', 'attico', 'loft', 'mansarda']\n",
    "\n",
    "\n",
    "all_features = numerical_features + categorical_features\n",
    "num_imputer = SimpleImputer(strategy='mean')  \n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "hot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "selector = PandasColumnSelector()\n",
    "featurizer = PandasFeatureEngineer(functions=CUSTOM_FEATURE_FUNCTIONS)\n",
    "\n",
    "\n",
    "# numerical pipeline\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('selector', PandasColumnSelector(columns=['superficie'])),\n",
    "    ('imputer', num_imputer),\n",
    "    ('scaler', StandardScaler()) \n",
    "])\n",
    "\n",
    "\n",
    "# categorical pipeline\n",
    "categorical_featurizer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('selector', PandasColumnSelector(columns=categorical_features), categorical_features),\n",
    "        ('bathrooms_featurizer', PandasFeatureEngineer(functions={\"bathrooms_feature\": bathrooms_featurizer}), ['bagni']),\n",
    "        ('rooms_featurizer', PandasFeatureEngineer(functions={\"rooms_feature\": rooms_featurizer}), ['stanze']), \n",
    "    ])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('categorical_featurizer', categorical_featurizer),\n",
    "    ('imputer', cat_imputer),\n",
    "    ('encoder', hot_encoder)\n",
    "])\n",
    "\n",
    "\n",
    "# final preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('numerical', numerical_pipeline, ['superficie']),\n",
    "    ('categorical', categorical_pipeline, categorical_features)\n",
    "], remainder='drop')\n",
    "\n",
    "\n",
    "# Create the target pipeline\n",
    "target_pipeline = Pipeline([\n",
    "    ('reshaper', TargetReshaper()),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "#%% CREATE X AND Y\n",
    "X = df.drop(columns=['prezzo'])\n",
    "y = df['prezzo']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "\n",
    "\n",
    "#%% FIRST LAYER DEEP LEARNING DEFAULT PARAMSÂ§\n",
    "BEST_PARAMS_FIRST_LAYER = {\n",
    "    # NN architecture\n",
    "    \"model\": build_model,\n",
    "    \"num_features\": 73,\n",
    "    \"num_labels\": 1,\n",
    "    \"hidden_units\": (128,) * 10,\n",
    "    \"dropout_rate\": 0.02,\n",
    "    # Model compilation,\n",
    "    \"optimizer\": \"adam\",\n",
    "    # \"optimizer__learning_rate\": 0.05,\n",
    "    \"loss\": \"log_cosh\",\n",
    "    \"metrics\": [\"mse\", \"mae\"],\n",
    "}\n",
    "\n",
    "X_transformed = preprocessor.fit_transform(X_train)\n",
    "y_transformed = target_pipeline.fit_transform(y_train)\n",
    "\n",
    "regressor = KerasRegressorWrapper(**BEST_PARAMS_FIRST_LAYER)\n",
    "regressor.fit(X_transformed, y_transformed)\n",
    "\n",
    "\n",
    "#%% MODEL PIPELINE NESTED 1 LEVEL\n",
    "regressor = KerasRegressorWrapper(build_fn=build_model)\n",
    "\n",
    "BEST_PARAMS_SECOND_LAYER = {\n",
    "    \"model__num_features\": 73,\n",
    "    \"model__num_labels\": 1,\n",
    "    \"model__hidden_units\": (128,) * 5,\n",
    "    \"loss\": \"log_cosh\",\n",
    "}\n",
    "\n",
    "regressor.set_params(**BEST_PARAMS_SECOND_LAYER)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', regressor)\n",
    "])\n",
    "\n",
    "y_transformer = target_pipeline.fit(y_train)\n",
    "y_train_transformed = target_pipeline.transform(y_train)\n",
    "pipeline.fit(X_train, y_train_transformed)\n",
    "\n",
    "#%% INSPECT VALUES\n",
    "current_params = regressor.get_params()\n",
    "for key, value in current_params.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "\n",
    "for param, value in BEST_PARAMS_SECOND_LAYER.items():\n",
    "    current_value = regressor.get_params().get(param)\n",
    "    print(f\"{param}: {current_value} (Expected: {value})\")\n",
    "\n",
    "\n",
    "\n",
    "#%% GRIDSEARCH\n",
    "regressor = KerasRegressorWrapper(build_fn=build_model)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('modelL2', regressor)\n",
    "])\n",
    "\n",
    "regressor.set_params(**BEST_PARAMS_SECOND_LAYER)\n",
    "\n",
    "param_grid = {\n",
    "    'modelL2__model__hidden_units': [(128, 128, 128)],\n",
    "    'modelL2__model__dropout_rate': [0.1],\n",
    "    'modelL2__model__optimizer': ['adam'],\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, \n",
    "                           param_grid=param_grid,\n",
    "                           cv=2, \n",
    "                           verbose=1, \n",
    "                           n_jobs=-1, \n",
    "                           scoring='neg_mean_absolute_error')\n",
    "\n",
    "grid_search.fit(X_train, y_train_transformed)\n",
    "\n",
    "\n",
    "#%% INSPECT VALUES\n",
    "current_params = regressor.get_params()\n",
    "for key, value in current_params.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "for param, value in BEST_PARAMS_SECOND_LAYER.items():\n",
    "    current_value = regressor.get_params().get(param)\n",
    "    print(f\"{param}: {current_value} (Expected: {value})\")\n",
    "\n",
    "#%% GRIDSEARCH - COMPARE MODELS\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model_placeholder', None)\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'model_placeholder': [RandomForestRegressor()],\n",
    "        'model_placeholder__n_estimators': [50, 100],\n",
    "    },\n",
    "    {\n",
    "        'model_placeholder': [KerasRegressorWrapper()],\n",
    "        'model_placeholder__model__hidden_units': [(128, 128, 128)],\n",
    "        'model_placeholder__model__dropout_rate': [0.1],\n",
    "        'model_placeholder__model__optimizer': ['adam'],\n",
    "    }\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                            param_grid=param_grid,\n",
    "                            cv=2,\n",
    "                            verbose=1,\n",
    "                            n_jobs=-1,\n",
    "                            scoring='neg_mean_absolute_error')\n",
    "\n",
    "grid_search.fit(X_train, y_train_transformed)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "#%% MODEL PIPELINE NESTED 2 LEVELS\n",
    "regressor = KerasRegressorWrapper(build_fn=build_model)\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('gridsearch', regressor)\n",
    "])\n",
    "\n",
    "BEST_PARAMS_SECOND_LAYER = {\n",
    "    \"model__num_features\": 73,\n",
    "    \"model__num_labels\": 1,\n",
    "    \"model__hidden_units\": (128,) * 5,\n",
    "    \"loss\": \"log_cosh\",\n",
    "}\n",
    "\n",
    "regressor.set_params(**BEST_PARAMS_SECOND_LAYER)\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'model': [KerasRegressorWrapper()], \n",
    "        \"gridsearch__model__dropout_rate\": [0.01, 0.02],\n",
    "        \"gridsearch__model__hidden_units\": [(128,)*10, (128,)*5],\n",
    "        # \"regressor__model__optimizer\": ['adam', 'adagrad', 'adadelta', 'rsmsprop'], \n",
    "        # \"regressor__model__optimizer__learning_rate\": [0.05, 0.01],\n",
    "        # \"regressor__model__loss\": [\"log_cosh\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=2, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train_transformed)\n",
    "\n",
    "\n",
    "#%%\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=2, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train_transformed)\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "y_transformer = target_pipeline.fit(y_train)\n",
    "y_train_transformed = target_pipeline.transform(y_train)\n",
    "\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', regressor)\n",
    "])\n",
    "\n",
    "regressor.set_params()\n",
    "\n",
    "model_pipeline.fit(X_train, y_train_transformed)\n",
    "\n",
    "#%%\n",
    "\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'model': [RandomForestRegressor()],\n",
    "        'model__n_estimators': [50, 100],\n",
    "        #model__max_depth': [None, 10, 20],\n",
    "        #'model__min_samples_split': [2, 5],\n",
    "    }, \n",
    "    {\n",
    "        'model': [KerasRegressorWrapper()], \n",
    "        \"model__model__dropout_rate\": [0.01, 0.02],\n",
    "        \"model__model__hidden_units\": [(128,)*10, (128,)*5],\n",
    "        # \"regressor__model__optimizer\": ['adam', 'adagrad', 'adadelta', 'rsmsprop'], \n",
    "        # \"regressor__model__optimizer__learning_rate\": [0.05, 0.01],\n",
    "        # \"regressor__model__loss\": [\"log_cosh\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(model_pipeline, param_grid, cv=2, verbose=1, n_jobs=-1)\n",
    "\n",
    "\n",
    "# split and prepare data\n",
    "X = df.drop(columns=['prezzo'])\n",
    "y = df['prezzo']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "y_transformer = target_pipeline.fit(y_train)\n",
    "y_transformed = target_pipeline.transform(y_train)\n",
    "\n",
    "# apply gridsearch\n",
    "grid_search.fit(X_train, y_transformed)\n",
    "\n",
    "# Print the best parameters and model\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "print(\"Best estimator:\\n{}\".format(grid_search.best_estimator_))\n",
    "\n",
    "\n",
    "#%%\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', regressor)\n",
    "])\n",
    "\n",
    "for param_name, param_value in best_params.items():\n",
    "    #if param_name.startswith('model__'):\n",
    "    print(param_name, param_value)\n",
    "\n",
    "\n",
    "grid_search.best_estimator_.fit(X_train, y_transformed)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "X = df.drop(columns=['prezzo'])\n",
    "y = df['prezzo']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "\n",
    "y_transformer = target_pipeline.fit(y_train)\n",
    "y_transformed = target_pipeline.transform(y_train)\n",
    "\n",
    "model_pipeline.fit(X_train, y_transformed)\n",
    "y_st = model_pipeline.predict(X_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %%\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
